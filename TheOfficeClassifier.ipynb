{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Laura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Laura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')  \n",
    "nltk.download('wordnet')  \n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pd.read_csv(\"the-office-lines-simplified.csv\")\n",
    "michael = pd.read_csv(\"michael-not-michael.csv\")\n",
    "six_classes = pd.read_csv(\"6-classes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = {\n",
    "    \"Michael\":1,\"Dwight\":2,\"Jim\":3,\"Pam\":4,\"Andy\":5,\"Kevin\":6,\"Angela\":7,\n",
    "    \"Oscar\":8,\"Erin\":9,\"Ryan\":10,\"Darryl\":11,\"Phyllis\":12,\"Kelly\":13,\"Jan\":14,\"Toby\":15,\"Other\":16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters6 = {\n",
    "    \"Michael\":1,\"Dwight\":2,\"Jim\":3,\"Pam\":4,\"Andy\":5,\"Other\":6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Distribution of lines by character in \"The Office\"')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEzCAYAAAD5Hp7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmYXFWd//H3BwKCLLIFRLaARhxERQyCP8dxQREQBTeUcUHFiTqoqKigoiC44Iyi4g4jsogsLigqDtsIwqMsiYJhUyIECCBb2FWE8Pn9cU6Tm6a6uxJuVaW7P6/nqaerzt2+t7qqvveec+65sk1EREQblht0ABERMXEkqURERGuSVCIiojVJKhER0ZoklYiIaE2SSkREtCZJZQAkfVvSJ1ta18aS7pO0fH19jqR3trHuur5fSdqzrfUtwXY/I+l2SX/tMO1FkuY3Xl8u6UV9jG2x7fdoG9MkWdKUXm5nUOpndrM+bavn/68O23y+pKvrfu4maT1Jv5F0r6QvSfq4pP/pZ0z9kqTSMknzJP29fnjukvRbSe+W9Mh7bfvdtg/pcl0vHW0e29fbXtX2whZiP0jS94etfyfbxzzWdS9hHBsB+wJb2H7iWPPbfrrtc3oe2CRVk9tT2lxn/cxesxSxTJM0rz6fV1//qv543yfpQUn/bLz+dptx1+1uKOl4SXdIul/SRZJ2GTbbwcDX637+FJgJ3A6sbntf25+z/ZgO/mqyPKc+X2YuOExS6Y1X2l4N2AQ4FNgP+G7bG5moR7GU9+0O27cOOpCJYJCfk35sux74rGp7VeB44L+GXtt+d5vbkrQWcD7wT+DpwDrAl4EfSHpdY9ZNgMuHvb7Ck+Fqc9t5tPgA5gEvHVb2XOBhYMv6+mjgM/X5OsAvgLuABcB5lGR/XF3m78B9wEeBaYCBvYDrgd80yqbU9Z0DfB64CLgb+BmwVp32ImB+p3iBHSlflAfr9i5trO+d9flywAHAdcCtwLHAE+q0oTj2rLHdDnxilPfpCXX52+r6Dqjrf2nd54drHEd3WHax/Wi+58BBwMl13fdSvtgzGvM+Cfhx3e61wPuH/Z9mAfcAtwCHjRD7i4D5wMfrfs4D3lSnbVOXndKY/7XAJSOsa2XgS/U9uJvyg7XyWO9njfV3lM/NzcDXgRUb0w3sDVwNXFvLvgrcUPdvNvCCxvzL1/35S33fZgMbUT5jBu6v/4831Pl3AS6p2/8t8Mxh/4/9gD8CDzTfi2HxPaXxffgG8Mu67QuBJ4/wfk0D5jW2M23Y9KOp360O/699KZ/bm4G3N6Y/DvhifZ9vAb4NrDzC9g8BLgOWG1a+X/0fqr6Hze/uCZTv1T/r65dSPqffbyz/r/V9vKv+j942Vmx1v84Zej8H/dv3yL4MOoCJ9qBDUqnl1wPvqc8f+eBTEsC3gRXq4wWAOq2LRT80xwKrsPiPTzOp3AhsWef58dCHl1GSSn2+2Ae9sb6hpPIOYC6wGbAq8BPguGGxHVnjehblB+VfRnifjqUkvNXqsn8G9hopzmHLLja9wz78A9iZ8kP5eeCCOm05yo/lp4AV635cA7y8Tv8d8Jb6fFVgu1G2/xBwGOVL/0LKj+7mdfoVwE6N+U8B9h1hXd+o7/EGNd7/V9c56vsJPAfYDphS570S+EBjvQbOBNZi0Y/Qm4G16zL7An8FVqrTPgLMATan/DA+C1i7sa6nNNa9NeXHedsa8571f/C4xv/jEkpSGunHeXhSWUBJlFMoZxsnLuX372g6J5WHKFVSK9TPxt+ANev0rwCn1vdqNeDnwOdHWP8FwKc7lG9a92noMzCPxb+7i8VF47sGbExJpnvU+NYGtlrS2JaVR6q/+ucmygdjuAeB9YFNbD9o+zzXT9MoDrJ9v+2/jzD9ONuX2b4f+CSw+1BD/mP0JsrR+zW27wM+BrxxWBXHp23/3falwKWUH6fF1FjeAHzM9r2251GO1t/SQowA59s+zaWd6bhGDNsAU20fbPufLnX6RwJvrNMfBJ4iaR3b99m+YIztfNL2A7bPpRxl717Lj6H8gA9Vl7wc+MHwhWs72zuAfWzfaHuh7d/afqAxW8f30/Zs2xfYfqi+f9+hJLemz9teMPQ5sf1923fUZb5ESV6b13nfCRxg+08uLrV9xwj7/R/Ad2xfWGM+hpLwtmvMc7jtG0b5jA73E9sX2X6IklS26nK5bj0IHFy/Y6dRzhg2lyTK/nywvlf3Ap9j0WdiuHUoZzrD3dyYvqTeBJxl+4Qa3x22L1mK2JYJE7VOflm0AeVobLj/phy1nFE+Qxxh+9Ax1nXDEky/jnL0szQf9uGeVNfXXPcUYL1GWbO31t8oR/zDrUM5Uxi+rg1aiLFTDCvVxLcJ8CRJdzWmL0+pcoRSrXgwcJWkayk/6L8YYRt31qQ95DrK+wPwfeBKSatSEs15tjv9EK0DrESpLul2X1YFkPRUypnSDODxlP/D7GHLLvY5kbQvJXk8iXJUvTqLPhcbjRFH0ybAnpLe1yhbkUX7/6htd6Gbz81jcUdNWMO3MZXy/s2u3z8oZ2ojHYTdTjkIHG79xvQlNdJ7v6SxLRNyptIHkrah/GCeP3xaPVLf1/ZmwCuBD0nafmjyCKsc60xmo8bzjSlHabdTqmge34hrecoHt9v13kT5QWmu+yFKXe+SuL3GNHxdNy7hepbUDZT2hTUaj9Vs7wxg+2rbewDrAl8AfiRplRHWteawaRtT3h9s30ipSns15ezruBHWcTulqu7JS7Ev3wKuAqbbXp3SHqJh8zzy/5T0Akq9/+6Uap81KG04Q8vcsARx3AB8dtj7+HjbJ3Ta9jLudkrbx9Mb+/IEl0b/Ts4CXtvszVntTnlf/rwUMYz03i9pbMuEJJUekrR67Wp4IqX+dE6HeXaR9JR6qnsPsLA+oPxYL01f/jdL2kLS4ylH3j+qVUF/phy1v0LSCpTG8cc1lrsFmNbhCzPkBOCDkjatR+GfA04adgQ4phrLycBnJa0maRPgQ5Qj/F66CLhH0n6SVpa0vKQta9JH0pslTbX9MKXBFBb9Lzr5tKQV6w/2LsAPG9OOpXSueAalTeVR6naOAg6T9KQaz/MkPa7T/MOsRvm83CfpacB7upj/IUoHhSmSPkU5UxnyP8AhkqareKakteu04Z/DI4F3S9q2zrtK/Uyt1kXcy5T6PzgS+LKkdQEkbSDp5SMs8mXK+/ZdSU+UtJKkPYBPAB/pouq6k+OBl0raXdIUSWtL2mopYlsmJKn0xs8l3Us5AvkEpZri7SPMO51y9HMf5ej2m150zcXngQPq9S4fXoLtH0dpGPwrpXrl/QC27wb+k/IDciPlzKV5UdjQj+Idkn7fYb1H1XX/htJz6h/A+zrM14331e1fQzmD+0Fdf8/UZPZKSn39tZQjwf+h9ESD0gPuckn3UXpKvdH2P0ZY3V+BOylnJ8cD77Z9VWP6KZQzsVOGVZMN92FKA/nFlOrRL9Dd9/LDwL9TGniPBE4aY/7TgV9RDiyuo/zvmlVUh1ES/RmUZPVdSgcBKNWzx9TP4e62Z1Hq+r9OeQ/mAm/rIuZl1X6UfbhA0j2U7+PmnWas7Uz/SvleXQHcQTkgeovtsf4HHdm+ntJ5YF/KZ+ASFrUDdh3bskJLl1gjYiyS/gK8y/ZZg44lol9yphLRA5JeS2lX+L9BxxLRT+n9FdGyOnTGFpQqkYcHHE5EX6X6KyIiWpPqr4iIaE3PkoqkjST9WtKVKkOT71PLD5J0o6RL6mPnxjIfkzRX0p+a3eYk7VjL5krav1G+qaQLVYaYPknSir3an4iIGFvPqr8krQ+sb/v3tf/6bGA3ykVC99n+4rD5t6BcB/FcypW5ZwFPrZP/DLyM0v31YmAP21dIOpkyvMOJKkNcX2r7W6PFtc4663jatGlt7WZExKQwe/bs221PHWu+njXU12Epbq7P75V0JaMPw7ErZRC5B4BrJc2lJBiAuXWcJiSdCOxa1/cSSl99KOMtHUS50nhE06ZNY9asWUu3UxERk5Sk68aeq09tKpKmAc+mDGkN8F5Jf5R0lKQ1a9kGLH4x1vxaNlL52sBdjau5h8o7bX+mpFmSZt12220t7FFERHTS86RSh/P4MWVY7nsoZxJPplzVfDNldFp49LhFUPr5L2n5owvtI2zPsD1j6tQxz94iImIp9fQ6lTq+1I+B423/BMD2LY3pR1JuUAXlTKM5EOKG1AH6Rii/HVhD0pR6ttKcPyIiBqCXvb9EGT/oStuHNcqbw0a/mnIXNSg3onmjpMdJ2pQyJtZFlIb56bWn14qUewmcWgdu+zUwdAvPPSk3fYqIiAHp5ZnK8ynDfs+RdEkt+ziwh6StKFVV84B3Adi+vPbmuoIymuredQBAJL2XMiDe8sBRtofu/bwfcKKkzwB/oAf3gY+IiO5NuivqZ8yY4fT+iohYMpJm254x1ny5oj4iIlqTpBIREa3JKMVLYNr+vxx0CF2Zd+grBh1CRExSOVOJiIjWJKlERERrklQiIqI1SSoREdGaJJWIiGhNkkpERLQmSSUiIlqTpBIREa1JUomIiNYkqURERGuSVCIiojVJKhER0ZoklYiIaE2SSkREtCZJJSIiWpOkEhERrUlSiYiI1iSpREREa5JUIiKiNUkqERHRmiSViIhoTZJKRES0JkklIiJak6QSERGtSVKJiIjWJKlERERrklQiIqI1SSoREdGaJJWIiGhNkkpERLQmSSUiIlrTs6QiaSNJv5Z0paTLJe1Ty9eSdKakq+vfNWu5JB0uaa6kP0raurGuPev8V0vas1H+HElz6jKHS1Kv9iciIsbWyzOVh4B9bf8LsB2wt6QtgP2Bs21PB86urwF2AqbXx0zgW1CSEHAgsC3wXODAoURU55nZWG7HHu5PRESMoWdJxfbNtn9fn98LXAlsAOwKHFNnOwbYrT7fFTjWxQXAGpLWB14OnGl7ge07gTOBHeu01W3/zraBYxvrioiIAehLm4qkacCzgQuB9WzfDCXxAOvW2TYAbmgsNr+WjVY+v0N5p+3PlDRL0qzbbrvtse5ORESMoOdJRdKqwI+BD9i+Z7RZO5R5KcofXWgfYXuG7RlTp04dK+SIiFhKPU0qklagJJTjbf+kFt9Sq66of2+t5fOBjRqLbwjcNEb5hh3KIyJiQHrZ+0vAd4ErbR/WmHQqMNSDa0/gZ43yt9ZeYNsBd9fqsdOBHSStWRvodwBOr9PulbRd3dZbG+uKiIgBmNLDdT8feAswR9IltezjwKHAyZL2Aq4HXl+nnQbsDMwF/ga8HcD2AkmHABfX+Q62vaA+fw9wNLAy8Kv6iIiIAelZUrF9Pp3bPQC27zC/gb1HWNdRwFEdymcBWz6GMCMiokW5oj4iIlqTpBIREa1JUomIiNYkqURERGuSVCIiojVJKhER0ZoklYiIaE2SSkREtCZJJSIiWpOkEhERrUlSiYiI1iSpREREa5JUIiKiNUkqERHRmiSViIhoTZJKRES0JkklIiJak6QSERGtSVKJiIjWJKlERERrxkwqkvaRtLqK70r6vaQd+hFcRESML92cqbzD9j3ADsBU4O3AoT2NKiIixqVukorq352B79m+tFEWERHxiG6SymxJZ1CSyumSVgMe7m1YERExHk3pYp69gK2Aa2z/TdLalCqwiIiIxXRzpmJgC+D99fUqwEo9iygiIsatbpLKN4HnAXvU1/cC3+hZRBERMW51U/21re2tJf0BwPadklbscVwRETEOdXOm8qCk5SnVYEiaShrqIyKig26SyuHAKcC6kj4LnA98rqdRRUTEuDRm9Zft4yXNBranXJ+ym+0rex5ZRESMO920qQBcDdwzNL+kjW1f37OoIiJiXBozqUh6H3AgcAuwkHK2YuCZvQ0tIiLGm27OVPYBNrd9R6+DiYiI8a2bhvobgLuXdMWSjpJ0q6TLGmUHSbpR0iX1sXNj2sckzZX0J0kvb5TvWMvmStq/Ub6ppAslXS3ppHRzjogYvG6SyjXAOfVH/0NDjy6WOxrYsUP5l21vVR+nAUjaAngj8PS6zDclLV+7Mn8D2IlyVf8edV6AL9R1TQfupAwnExERA9RNUrkeOBNYEVit8RiV7d8AC7qMY1fgRNsP2L4WmAs8tz7m2r7G9j+BE4FdJQl4CfCjuvwxwG5dbisiInqkmy7Fn255m++V9FZgFrCv7TuBDYALGvPMr2VQqt+a5dsCawN32X6ow/yPImkmMBNg4403bmMfIiKigxHPVCR9pf79uaRThz+WcnvfAp5MGfX4ZuBLQ5vrMK+Xorwj20fYnmF7xtSpU5cs4oiI6NpoZyrH1b9fbGtjtm8Zei7pSOAX9eV8YKPGrBsCN9XnncpvB9aQNKWerTTnj4iIARkxqdieXf+e29bGJK1v++b68tXAUM+wU4EfSDoMeBIwHbiIckYyXdKmwI2Uxvx/t21JvwZeR2ln2RP4WVtxRkTE0hkxqUiaw+hVSqNe/CjpBOBFwDqS5lMuoHyRpK3qeucB76rrulzSycAVwEPA3rYX1vW8FzgdWB44yvbldRP7ASdK+gzwB+C7Y+1sRET01mjVX7s8lhXb3qND8Yg//LY/C3y2Q/lpwGkdyq+h9A6LiIhlxGjVX9f1M5CIiBj/urlOJSIioitJKhER0ZrRrlM5u/79Qv/CiYiI8Wy0hvr1Jb0QeJWkExl2waHt3/c0soiIGHdGSyqfAvanXFh42LBppoy9FRER8YjRen/9CPiRpE/aPqSPMUVExDjVzYCSh0h6FfBvtegc278YbZmIiJicxuz9JenzlLs/XlEf+9SyiIiIxXRzO+FXAFvZfhhA0jGUYVE+1svAIiJi/On2OpU1Gs+f0ItAIiJi/OvmTOXzwB/qqMCitK3kLCUiIh6lm4b6EySdA2xDSSr72f5rrwOLiIjxp5szFeo9UJb2bo8RETFJZOyviIhoTZJKRES0ZtSkImk5SZeNNk9ERMSQUZNKvTblUkkb9ymeiIgYx7ppqF8fuFzSRcD9Q4W2X9WzqCIiYlzqJql8uudRxEBM2/+Xgw6hK/MOfcWgQ4iILnVzncq5kjYBpts+S9LjgeV7H1pERIw33Qwo+R/Aj4Dv1KINgJ/2MqiIiBifuulSvDfwfOAeANtXA+v2MqiIiBifukkqD9j+59ALSVMod36MiIhYTDdJ5VxJHwdWlvQy4IfAz3sbVkREjEfdJJX9gduAOcC7gNOAA3oZVEREjE/d9P56uN6Y60JKtdefbKf6KyIiHmXMpCLpFcC3gb9Qhr7fVNK7bP+q18FFRMT40s3Fj18CXmx7LoCkJwO/BJJUIiJiMd20qdw6lFCqa4BbexRPRESMYyOeqUh6TX16uaTTgJMpbSqvBy7uQ2wRETHOjFb99crG81uAF9bntwFr9iyiiIgYt0ZMKrbf3s9AIiJi/Oum99emwPuAac35M/R9REQM101D/U+BecDXKD3Bhh6jknSUpFubd46UtJakMyVdXf+uWcsl6XBJcyX9UdLWjWX2rPNfLWnPRvlzJM2pyxwuSV3vdURE9EQ3SeUftg+3/Wvb5w49uljuaGDHYWX7A2fbng6cXV8D7ARMr4+ZwLegJCHgQGBb4LnAgUOJqM4zs7Hc8G1FRESfdZNUvirpQEnPk7T10GOshWz/BlgwrHhX4Jj6/Bhgt0b5sS4uANaQtD7wcuBM2wts3wmcCexYp61u+3f16v5jG+uKiIgB6ebix2cAbwFeAjxcy1xfL6n1bN8MYPtmSUND6G8A3NCYb34tG618fofyjiTNpJzVsPHGGy9F2BER0Y1uksqrgc2aw9/3QKf2EC9FeUe2jwCOAJgxY0bGLYuI6JFuqr8uBdZoaXu31Kor6t+hK/PnAxs15tsQuGmM8g07lEdExAB1k1TWA66SdLqkU4ceS7m9U4GhHlx7Aj9rlL+19gLbDri7VpOdDuwgac3aQL8DcHqddq+k7Wqvr7c21hUREQPSTfXXgUuzYkknAC8C1pE0v67nUOBkSXsB11OGfIFyj5adgbnA34C3A9heIOkQFg0Lc7Dtocb/91B6mK1MGdwyA1xGRAxYN/dT6ab7cKfl9hhh0vYd5jWw9wjrOQo4qkP5LGDLpYktIiJ6o5sr6u9lUSP4isAKwP22V+9lYBERMf50c6ayWvO1pN0oFyJGREQsppuG+sXY/ilLd41KRERMcN1Uf72m8XI5YAajXBMSERGTVze9v5r3VXmIMrjkrj2JJiIixrVu2lRyX5WIiOjKaLcT/tQoy9n2IT2IJyIixrHRzlTu71C2CrAXsDaQpBIREYsZ7XbCj9yIS9JqwD6UK91PpIubdEVExOQzaptKvUnWh4A3Ue5/snW9r0lERMSjjNam8t/AayhDxj/D9n19iyoiIsal0S5+3Bd4EnAAcJOke+rjXkn39Ce8iIgYT0ZrU1niq+0jImJyS+KIiIjWJKlERERrklQiIqI13Yz9FTFuTNv/l4MOoSvzDn3FoEOI6ImcqURERGuSVCIiojVJKhER0ZoklYiIaE2SSkREtCa9vyKWYenNFuNNzlQiIqI1SSoREdGaJJWIiGhNkkpERLQmSSUiIlqTpBIREa1JUomIiNYkqURERGuSVCIiojVJKhER0ZoklYiIaM1Axv6SNA+4F1gIPGR7hqS1gJOAacA8YHfbd0oS8FVgZ+BvwNts/76uZ0/ggLraz9g+pp/7ERFLLuOZTWyDPFN5se2tbM+or/cHzrY9HTi7vgbYCZheHzOBbwHUJHQgsC3wXOBASWv2Mf6IiBhmWar+2hUYOtM4BtitUX6siwuANSStD7wcONP2Att3AmcCO/Y76IiIWGRQScXAGZJmS5pZy9azfTNA/btuLd8AuKGx7PxaNlL5o0iaKWmWpFm33XZbi7sRERFNg7qfyvNt3yRpXeBMSVeNMq86lHmU8kcX2kcARwDMmDGj4zwREfHYDeRMxfZN9e+twCmUNpFbarUW9e+tdfb5wEaNxTcEbhqlPCIiBqTvSUXSKpJWG3oO7ABcBpwK7Fln2xP4WX1+KvBWFdsBd9fqsdOBHSStWRvod6hlERExIIOo/loPOKX0FGYK8APb/yvpYuBkSXsB1wOvr/OfRulOPJfSpfjtALYXSDoEuLjOd7DtBf3bjYiIGK7vScX2NcCzOpTfAWzfodzA3iOs6yjgqLZjjIiIpbMsdSmOiIhxLkklIiJak6QSERGtGdR1KhERE0LGMltczlQiIqI1SSoREdGaJJWIiGhNkkpERLQmSSUiIlqTpBIREa1JUomIiNYkqURERGuSVCIiojVJKhER0ZoklYiIaE2SSkREtCZJJSIiWpOkEhERrUlSiYiI1iSpREREa5JUIiKiNUkqERHRmiSViIhoTZJKRES0JkklIiJak6QSERGtSVKJiIjWJKlERERrklQiIqI1SSoREdGaJJWIiGhNkkpERLQmSSUiIlqTpBIREa0Z90lF0o6S/iRprqT9Bx1PRMRkNq6TiqTlgW8AOwFbAHtI2mKwUUVETF7jOqkAzwXm2r7G9j+BE4FdBxxTRMSkJduDjmGpSXodsKPtd9bXbwG2tf3eYfPNBGbWl5sDf+pi9esAt7cY7niSfZ+csu+TU7f7vontqWPNNOWxxzNQ6lD2qCxp+wjgiCVasTTL9oylDWw8y75n3yeb7Ht7+z7eq7/mAxs1Xm8I3DSgWCIiJr3xnlQuBqZL2lTSisAbgVMHHFNExKQ1rqu/bD8k6b3A6cDywFG2L29p9UtUXTbBZN8np+z75NTqvo/rhvqIiFi2jPfqr4iIWIYkqURERGuSVCIiojXjuqE+2iNpU9vXjlU2kUhaA3grMI3Gd8H2+wcVU/SHpLVsLxh0HP0maTlgO9u/7dk20lAPkr5Gh4smh0yGHxlJv7e99bCy2bafM6iYek3Sb4ELgDnAw0Plto8ZWFB9JmkX4BBgE0piFWDbqw80sB6TdDVwCfA94FeeRD+Ekn5n+3m9Wn/OVIpZgw5gUCQ9DXg68ARJr2lMWh1YaTBR9c1Ktj806CAG7CvAa4A5k+mHFXgq8FLgHcDXJJ0EHG37z4MNqy/OkPRa4Ce9+J/nTKUDSavYvn/QcfSDpF2B3YBXsfiFo/cCJ/byNHnQJH0QuA/4BfDAUPlkqhaR9Gtge9sPjznzBCXpxcD3gVWAS4H9bf9usFH1jqR7Kfu6EPg7LZ+dJqk0SHoe8F1gVdsbS3oW8C7b/zng0HpO0vMm8hepE0l7A58F7mJR9adtbza4qPpL0jaU6q9zWTyxHjawoPpA0trAm4G3ALdQvvenAlsBP7S96QDDG9dS/bW4rwAvpx6x275U0r8NNqS+mSvp4zy60fodA4uo9z4EPMX2ZB2dFkpSvY9S1bnigGPpp98BxwG72Z7fKJ8l6dsDiqkvJAl4E7Cp7UMkbQSsb/uiNtafpDKM7RvKe/6IhYOKpc9+BpwHnMXk2efLgb8NOogBW8v2DoMOYgA2H6k9wfYX+h1Mn32T0jHlJZSz1PsoNzvcpo2VJ6ks7gZJ/w9wHaDy/cCVA46pXx5ve79BB9FnC4FLartCs+pnwvf2azhL0g62zxh0IP0g6efUqs5hB48A2H5Vv2MagG1tby3pDwC276y/d61IUlncu4GvAhtQhtU/A9h7oBH1zy8k7Wz7tEEH0kc/rY/JbG/go5IeAB5k4ncp/mL9+xrgiZQGeoA9gHmDCGgAHqy3Yh9KrlNpdKl/rNJQP8nVniCm/JisQjlinww/LjGJSfqN7X8bq2wikvQm4A3A1sAxwOuAA2z/sI3150ylQdJKwF6U6zYeuUZjIjdW215t0DH0m6STbe8uaQ6LX/Q6lEifOaDQBkLSmsB0Fv/M/2ZwEfXFVEmb2b4GyugRwJi3yp0IbB8vaTawPeUzv5vt1qr5k1QWdxxwFaUH2MGUHhKTok1F0tYdiu8GrrP9UL/j6bGhNpNd6JBU+h/O4Eh6J7AP5a6plwDbUXpGvWSQcfXBB4FzJF1TX08D3jW4cPruauAeag6QtLHt69tYcaq/GiT9wfazJf3R9jMlrQCcbnuif8GQdAHldHhOLXoG5UKwtYF3T6SG3EaVXycPAH8BPmH77P5FNRj1bG0b4AK+zg6BAAAHrklEQVTbW9URFj5t+w0DDq3nJD0OeFp9eZXtB0abf6KQ9D7gQMr1OQtp+Qw9ZyqLe7D+vUvSlsBfKUcwk8E8YK+hO2dK2gL4CKXL4U8onRYmhNGq/GoD5pbA8fXvRPcP2/+QhKTH2b5K0uaDDqpPnsOi67KeJQnbxw42pL7Yh9Kl+o5erDxJZXFH1PrlT1IugFwV+NRgQ+qbpzVvxWz7CknPtn1Np66XE5XthcCldZDRyWB+Ha35p8CZku4EbhpwTD0n6TjgyZQqv6HrsgxMhqRyA6VquydS/RUA1AH1FgAn1qI3AOtQhrE433YrF0bFskvSC4EnAP9r+5+DjqeXJF0JbDGZBtGUNDR46tOBzYFf0oOheXKm0lDrWF/Lo4cqOXhQMfXR24D/BD5AqWM9H/gwpUrwxYMLK3qh9nR8N/AUSjvad22fO9io+uoyynUqNw86kD4aqva9vj5WZNHQPK0l15ypNEj6X8pp4WwaQ5XY/tLAgorogXpm+iBlaJ6dKL389hlsVP1TR1HYCriIRUfrtr3r4KLqD0mvH35NSqeypV5/ksoiki6zPRkaZx8xyjUbAEy2azYmC0lzbD+jPp8CXDT8Jm0TWa3qe+Ql8K/AHrafPqCQ+maEG/I9qmxppfprcb+V9Azbc8aedcIYOjrdZaBRRL8N9XTE9kOTqTMGgO1zJW0F/DuwO3AtMNFHJ94J2BnYQNLhjUmrA61di5akwiN99U15P95eL4h6gElwhbXtoTrl7YHzbF89yHiib54l6Z76XMDK9fWEHp5H0lOBN1LG+roDOIlSYzMZ2g1votzl9vXAnym/eQsp16t8sK2NJKkUOUovnRPeLGkTSpvSeZQkc8lAo4qesL38oGMYkKson+1X2p4Lj9wBdDK4gjJKyIqU2ygL2Aj4HuXup61Yrq0VjWe2r7N9HbA+sKDxegGlh8iEZ/tTdeSALSk9vz5CSS4RE8lrKRc1/1rSkZKGxr+aDP4LWBPYxPbWtp8NbEbpRv7FUZdcAmmob6j3F9h6qO+6pOWAWZOhAVPSAcDzKRd8/oGSWM5rVI9FTBiSVgF2o1SDvYQyWu8pE2k4ouEkXQ08dfi1OXUUiatsT29jOzlTWZyab7jth5k8VYSvoYzzdRZlWJZTk1BiorJ9v+3jbe/CosE09x9wWL3mThd71lEkWju7SFJZ3DWS3i9phfrYB7hmzKUmgHo2tj2l3/7LgDmSzh9sVBG9Z3uB7e9MgoFjr5D01uGFkt5MaWtqRaq/GiStCxxOOR02cDbwAdu3DjSwPqgDaL4AeCEwgzI+0Hm2J8vYZxETmqQNKLUQf6e0l5oyQvXKwKtt39jKdpJUAkDSL4HfUHrGXGz7wTEWiYhxSNJLKON/Cbi87Vs8JKkAkj5q+7/qyLSd6hzf32GxCafeqxrbtw06logYnyZLI/RYhu7uOGugUQyAyqXUBwJ7U9rYlpP0EPC1STKQZkS0KGcqk1y98GtnYKbta2vZZsC3KEOgf3mQ8UXE+JKkAkg6dbTptl/Vr1j6rV6b8zLbtw8rnwqcUS+QiojoSqq/iudRejudAFzI5LnCFmCF4QkFSruKpBUGEVBEjF9JKsUTKddm7EEZtfSXwAnN2+tOYKPd4W9C3/0vItqX6q9h6t0f9wD+GzjY9oS+V7mkhcD9nSYBK9nO2UpEdC1nKlVNJq+gJJRplIsgfzLImPphEo9WGxE9kDMVQNIxlNF5fwWcaPuyAYcUETEuJakAkh5mURVQ8w2Z0DcsiohoW5JKRES0JqMUR0REa5JUIiKiNUkqEUtA0hMlnSjpL5KukHSapJmSWrvHd5dxfLyf24voVpJKRJfq4JunAOfYfrLtLYCPA+s9xvUuTdf+JU4q9baxET2VpBLRvRcDD9r+9lCB7Uso96BZVdKPJF0l6fiagJD0KUkXS7pM0hGN8nMkfU7SucA+kl4p6UJJf5B0lqT16nyrSvqepDmS/ijptZIOBVaWdImk4+t8b5Z0US37zlACkXSfpIMlXUgZjiiip5JUIrq3JeWOeZ08G/gAsAWwGfD8Wv5129vY3pJyh71dGsusYfuFtr8EnA9sVwfwPBH4aJ3nk8Ddtp9h+5nA/9neH/i77a1sv0nSvwBvAJ5veytgIfCmuvwqwGW2t7Wd20NHz+WK+oh2XGR7PoCkSyijMpwPvFjSR4HHA2sBlwM/r8uc1Fh+Q+AkSesDKwLX1vKXAm8cmsn2nR22vT3wHODieiK0MjB0C+yFwI8f475FdC1JJaJ7lwOvG2HaA43nC4EpklYCvgnMsH2DpIOAlRrzNcdc+xpwmO1TJb0IOKiWiw53Ix1GwDG2P9Zh2j9sLxxj+YjWpPoronv/BzxO0n8MFUjaBnjhCPMPJZDbJa3KyAkJ4AnAjfX5no3yM4D3Nra3Zn36YOPWBGcDr5O0bp1nLUmbdLE/Ea1LUonoksvwE68GXla7FF9OOaO4aYT57wKOBOYAPwUuHmX1BwE/lHQe0Ly/zWeANWtD/6WUzgIARwB/lHS87SuAA4AzJP0ROBNYf+n2MuKxyTAtERHRmpypREREa5JUIiKiNUkqERHRmiSViIhoTZJKRES0JkklIiJak6QSERGtSVKJiIjW/H+y7zaBP0NdZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x204807dc828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(characters6.keys())\n",
    "print(n)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.hist(six_classes['speaker_id'], bins=n,rwidth=0.8)\n",
    "plt.xticks(np.arange(n),characters6.keys(),rotation=\"vertical\")\n",
    "plt.xlabel(\"Character\")\n",
    "plt.ylabel(\"Number of lines\")\n",
    "plt.title(\"Distribution of lines by character in \\\"The Office\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_testing(data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data['line_text'], data['speaker_id'], test_size=0.2)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47927,) (47927,)\n",
      "(11982,) (11982,)\n"
     ]
    }
   ],
   "source": [
    "# Generate training/testing splits\n",
    "X_train, X_test, y_train, y_test = get_training_testing(six_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(sent):\n",
    "    stripped = re.sub('[^\\w\\s]','',sent)\n",
    "    stripped = re.sub('_', ' ', stripped)\n",
    "    stripped = re.sub('\\s+', ' ', stripped)\n",
    "    stripped = stripped.strip()\n",
    "    return stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    predicted_train = clf.predict(X_train)\n",
    "    predicted_test = clf.predict(X_test)\n",
    "    print(\"Logistic Regression Training accuracy: \",np.mean(predicted_train == y_train))\n",
    "    print(\"Logistic Regression Testing accuracy: \", np.mean(predicted_test == y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(X_train, X_test, y_train, y_test):\n",
    "    clf_svc = LinearSVC().fit(X_train,y_train)\n",
    "    svm_predicted_train = clf_svc.predict(X_train)\n",
    "    svm_predicted_test = clf_svc.predict(X_test)\n",
    "    print(\"SVM Training accuracy: \",np.mean(svm_predicted_train == y_train))\n",
    "    print(\"SVM Testing accuracy: \", np.mean(svm_predicted_test == y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    clf = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted_train = clf.predict(X_train)\n",
    "    predicted_test = clf.predict(X_test)\n",
    "    print(\"Naive Bayes Training accuracy: \",np.mean(predicted_train == y_train))\n",
    "    print(\"Naive Bayes Testing accuracy: \", np.mean(predicted_test == y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(X_train, X_test, y_train, y_test):\n",
    "    clf = MLPClassifier().fit(X_train, y_train)\n",
    "    predicted_train = clf.predict(X_train)\n",
    "    predicted_test = clf.predict(X_test)\n",
    "    print(\"Neural Network Training accuracy: \",np.mean(predicted_train == y_train))\n",
    "    print(\"Neural Network Testing accuracy: \", np.mean(predicted_test == y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get raw count vectors using lemmatizer\n",
    "lemma_count_vect = CountVectorizer(tokenizer=LemmaTokenizer(),analyzer='word', token_pattern=r'\\w{1,}')\n",
    "lemma_X_train_counts =  lemma_count_vect.fit_transform(X_train)\n",
    "# get tf-idf vectors\n",
    "lemma_tfidf_transformer = TfidfTransformer()\n",
    "lemma_X_train_tfidf =  lemma_tfidf_transformer.fit_transform(lemma_X_train_counts)\n",
    "\n",
    "lemma_X_test_counts = lemma_count_vect.transform(X_test)\n",
    "lemma_X_test_tfidf = lemma_tfidf_transformer.transform(lemma_X_test_counts)\n",
    "\n",
    "lemma_X_train_tfidf,lemma_X_test_tfidf = scale_data(lemma_X_train_tfidf,lemma_X_test_tfidf)\n",
    "lemma_X_train_counts,lemma_X_test_counts = scale_data(lemma_X_train_counts,lemma_X_test_counts)\n",
    "\n",
    "n_components = 100\n",
    "print(\"Reducing dimensionality of tfidf scores to n =\", n_components)\n",
    "lemma_X_train_tfidf,lemma_X_test_tfidf = apply_pca(lemma_X_train_tfidf,lemma_X_test_tfidf,n_components)\n",
    "\n",
    "n_components = 100\n",
    "print(\"Reducing dimensionality to count scores to n =\", n_components)\n",
    "lemma_X_train_counts,lemma_X_test_counts = apply_pca(lemma_X_train_counts,lemma_X_test_counts,n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemmatized tf-idf scores.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python36\\Lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Training accuracy:  0.4761616625284287\n",
      "Neural Network Testing accuracy:  0.4041061592388583\n",
      "\n",
      "Logistic Regression Training accuracy:  0.4199303106808271\n",
      "Logistic Regression Testing accuracy:  0.41086629944917374\n",
      "\n",
      "SVM Training accuracy:  0.41990944561520643\n",
      "SVM Testing accuracy:  0.4114505090969788\n",
      "\n",
      "Using lemmatized count scores.\n",
      "Neural Network Training accuracy:  0.8284682955327894\n",
      "Neural Network Testing accuracy:  0.38516107494575197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using lemmatized tf-idf scores.\")\n",
    "neural_network(lemma_X_train_tfidf,lemma_X_test_tfidf,y_train,y_test)\n",
    "logistic_regression(lemma_X_train_tfidf,lemma_X_test_tfidf,y_train,y_test)\n",
    "svm(lemma_X_train_tfidf,lemma_X_test_tfidf,y_train,y_test)\n",
    "#naive_bayes(lemma_X_train_tfidf,lemma_X_test_tfidf,y_train,y_test)\n",
    "\n",
    "print(\"Using lemmatized count scores.\")\n",
    "neural_network(lemma_X_train_counts,lemma_X_test_counts,y_train,y_test)\n",
    "logistic_regression(lemma_X_train_counts,lemma_X_test_counts,y_train,y_test)\n",
    "svm(lemma_X_train_counts,lemma_X_test_counts,y_train,y_test)\n",
    "#naive_bayes(lemma_X_train_counts,lemma_X_test_counts,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    scaler.fit(X_train)\n",
    "    scaler.transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get raw count vectors\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "X_train_counts =  count_vect.fit_transform(X_train)\n",
    "# get tf-idf vectors\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf =  tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "X_train_tfidf,X_test_tfidf = scale_data(X_train_tfidf,X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training accuracy:  0.3185886869614205\n",
      "Naive Bayes Testing accuracy:  0.24261392088132197\n"
     ]
    }
   ],
   "source": [
    "nb_predicted_train = clf.predict(X_train_tfidf)\n",
    "nb_predicted_test = clf.predict(X_test_tfidf)\n",
    "print(\"Naive Bayes Training accuracy: \",np.mean(nb_predicted_train == y_train))\n",
    "print(\"Naive Bayes Testing accuracy: \", np.mean(nb_predicted_test == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will try using SVMs for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.5559914035929643\n",
      "Testing accuracy:  0.26322817559672845\n"
     ]
    }
   ],
   "source": [
    "clf_svc = LinearSVC().fit(X_train_tfidf,y_train)\n",
    "svm_predicted_train = clf_svc.predict(X_train_tfidf)\n",
    "svm_predicted_test = clf_svc.predict(X_test_tfidf)\n",
    "print(\"SVM Training accuracy: \",np.mean(svm_predicted_train == y_train))\n",
    "print(\"SVM Testing accuracy: \", np.mean(svm_predicted_test == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we apply PCA before classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(X_train, X_test, n_components=100):\n",
    "    pca = decomposition.TruncatedSVD(n_components = 100)\n",
    "    pca_X_train = pca.fit_transform(X_train)\n",
    "    pca_X_test = pca.transform(X_test)\n",
    "    return pca_X_train, pca_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (Low Dim) Training accuracy:  0.2733532246958917\n",
      "SVM (Low Dim) Testing accuracy:  0.25321315306292774\n"
     ]
    }
   ],
   "source": [
    "clf_svc = LinearSVC().fit(pca_X_train_tfidf,y_train)\n",
    "svm_predicted_train = clf_svc.predict(pca_X_train_tfidf)\n",
    "svm_predicted_test = clf_svc.predict(pca_X_test_tfidf)\n",
    "print(\"SVM (Low Dim) Training accuracy: \",np.mean(svm_predicted_train == y_train))\n",
    "print(\"SVM (Low Dim) Testing accuracy: \", np.mean(svm_predicted_test == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Naive Bayes on  1 -gram raw count scores.\n",
      "Naive Bayes Training accuracy:  0.8414255012832015\n",
      "Naive Bayes Testing accuracy:  0.7860958103822401\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-9e7499bd367e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Naive Bayes Testing accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNgram_predicted_test\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Naive Bayes \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" count vectors (train)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNgram_predicted_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Naive Bayes \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" count vectors (test)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNgram_predicted_test\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not int"
     ]
    }
   ],
   "source": [
    "# get raw count vectors\n",
    "errors = []\n",
    "ngrams = [1,2,3]\n",
    "for n in ngrams:\n",
    "    Ngram_count_vect = CountVectorizer(analyzer='word',stop_words=\"english\",ngram_range=(1,n))\n",
    "    Ngram_X_train_counts =  Ngram_count_vect.fit_transform(X_train)\n",
    "    Ngram_X_test_counts = Ngram_count_vect.transform(X_test)\n",
    "    \n",
    "    neural_network(X_test_tfidf,X_test_tfidf,y_test,y_test)\n",
    "     # fit NB model to N-gram raw counts\n",
    "    clf = MultinomialNB().fit(Ngram_X_train_counts, y_train)\n",
    "    \n",
    "    # run model on training and testing data using raw counts\n",
    "    Ngram_predicted_train = clf.predict(Ngram_X_train_counts)\n",
    "    Ngram_predicted_test = clf.predict(Ngram_X_test_counts)\n",
    "    print(\"Running Naive Bayes on \",n,\"-gram raw count scores.\")\n",
    "    print(\"Naive Bayes Training accuracy: \",np.mean(Ngram_predicted_train == y_train))\n",
    "    print(\"Naive Bayes Testing accuracy: \", np.mean(Ngram_predicted_test == y_test))\n",
    "    print()\n",
    "    errors.append([\"Naive Bayes \" + n + \" count vectors (train)\", np.mean(Ngram_predicted_train == y_train)])\n",
    "    errors.append([\"Naive Bayes \" + n + \" count vectors (test)\", np.mean(Ngram_predicted_test == y_test)])\n",
    "    \n",
    "    clf_svc = LinearSVC().fit(Ngram_X_train_counts,y_train)\n",
    "    svm_predicted_train = clf_svc.predict(Ngram_X_train_counts)\n",
    "    svm_predicted_test = clf_svc.predict(Ngram_X_test_counts)\n",
    "    print(\"Running SVM on \",n,\"-gram raw-count scores.\")\n",
    "    print(\"SVM Training accuracy: \",np.mean(svm_predicted_train == y_train))\n",
    "    print(\"SVM Testing accuracy: \", np.mean(svm_predicted_test == y_test))\n",
    "    print()\n",
    "    errors.append([\"SVM \" + n + \" count vectors (train)\", np.mean(svm_predicted_train == y_train)])\n",
    "    errors.append([\"SVM \" + n + \" count vectors (test)\", np.mean(svm_predicted_test == y_test)])\n",
    "    \n",
    "    # get tf-idf vectors\n",
    "    Ngram_tfidf_transformer = TfidfTransformer()\n",
    "    Ngram_X_train_tfidf =  Ngram_tfidf_transformer.fit_transform(Ngram_X_train_counts)\n",
    "    Ngram_X_test_tfidf = Ngram_tfidf_transformer.transform(Ngram_X_test_counts)\n",
    "\n",
    "    # fit model to N-gram tf-idfs\n",
    "    clf = MultinomialNB().fit(Ngram_X_train_tfidf, y_train)\n",
    "\n",
    "    # run model on training and testing data\n",
    "    Ngram_predicted_train = clf.predict(Ngram_X_train_tfidf)\n",
    "    Ngram_predicted_test = clf.predict(Ngram_X_test_tfidf)\n",
    "    print(\"Running Naive Bayes on \",n,\"-gram TF-IDF scores.\")\n",
    "    print(\"Naive Bayes Training accuracy: \",np.mean(Ngram_predicted_train == y_train))\n",
    "    print(\"Naive Bayes Testing accuracy: \", np.mean(Ngram_predicted_test == y_test))\n",
    "    print()\n",
    "    \n",
    "    clf_svc = LinearSVC().fit(Ngram_X_train_tfidf,y_train)\n",
    "    svm_predicted_train = clf_svc.predict(Ngram_X_train_tfidf)\n",
    "    svm_predicted_test = clf_svc.predict(Ngram_X_test_tfidf)\n",
    "    print(\"Running SVM on \",n,\"-gram TF-IDF scores.\")\n",
    "    print(\"SVM Training accuracy: \",np.mean(svm_predicted_train == y_train))\n",
    "    print(\"SVM Testing accuracy: \", np.mean(svm_predicted_test == y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Logistic Regression on  1 -gram raw count scores.\n",
      "Logistic Regression Training accuracy:  0.8448265069793645\n",
      "Logistic Regression Testing accuracy:  0.7958604573526957\n",
      "\n",
      "Running Logistic Regression on  1 -gram TF-IDF scores.\n",
      "Logistic Regression Training accuracy:  0.8061218102530933\n",
      "Logistic Regression Testing accuracy:  0.7905191120013353\n",
      "\n",
      "Running Logistic Regression on  2 -gram raw count scores.\n",
      "Logistic Regression Training accuracy:  0.9096125357314249\n",
      "Logistic Regression Testing accuracy:  0.7981972959439159\n",
      "\n",
      "Running Logistic Regression on  2 -gram TF-IDF scores.\n",
      "Logistic Regression Training accuracy:  0.7995910447138356\n",
      "Logistic Regression Testing accuracy:  0.7912702386913704\n",
      "\n",
      "Running Logistic Regression on  3 -gram raw count scores.\n",
      "Logistic Regression Training accuracy:  0.9230079078598702\n",
      "Logistic Regression Testing accuracy:  0.801118344182941\n",
      "\n",
      "Running Logistic Regression on  3 -gram TF-IDF scores.\n",
      "Logistic Regression Training accuracy:  0.7990902831389405\n",
      "Logistic Regression Testing accuracy:  0.7912702386913704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngrams = [1,2,3]\n",
    "for n in ngrams:\n",
    "    Ngram_count_vect = CountVectorizer(analyzer='word',stop_words=\"english\",ngram_range=(1,n))\n",
    "    Ngram_X_train_counts =  Ngram_count_vect.fit_transform(X_train)\n",
    "    Ngram_X_test_counts = Ngram_count_vect.transform(X_test)\n",
    "    \n",
    "     # fit NB model to N-gram raw counts\n",
    "    clf = LogisticRegression().fit(Ngram_X_train_counts, y_train)\n",
    "    \n",
    "    # run model on training and testing data using raw counts\n",
    "    Ngram_predicted_train = clf.predict(Ngram_X_train_counts)\n",
    "    Ngram_predicted_test = clf.predict(Ngram_X_test_counts)\n",
    "    print(\"Running Logistic Regression on \",n,\"-gram raw count scores.\")\n",
    "    print(\"Logistic Regression Training accuracy: \",np.mean(Ngram_predicted_train == y_train))\n",
    "    print(\"Logistic Regression Testing accuracy: \", np.mean(Ngram_predicted_test == y_test))\n",
    "    print()\n",
    "    \n",
    "    # get tf-idf vectors\n",
    "    Ngram_tfidf_transformer = TfidfTransformer()\n",
    "    Ngram_X_train_tfidf =  Ngram_tfidf_transformer.fit_transform(Ngram_X_train_counts)\n",
    "    Ngram_X_test_tfidf = Ngram_tfidf_transformer.transform(Ngram_X_test_counts)\n",
    "\n",
    "    # fit model to N-gram tf-idfs\n",
    "    clf = MultinomialNB().fit(Ngram_X_train_tfidf, y_train)\n",
    "\n",
    "    # run model on training and testing data\n",
    "    Ngram_predicted_train = clf.predict(Ngram_X_train_tfidf)\n",
    "    Ngram_predicted_test = clf.predict(Ngram_X_test_tfidf)\n",
    "    print(\"Running Logistic Regression on \",n,\"-gram TF-IDF scores.\")\n",
    "    print(\"Logistic Regression Training accuracy: \",np.mean(Ngram_predicted_train == y_train))\n",
    "    print(\"Logistic Regression Testing accuracy: \", np.mean(Ngram_predicted_test == y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted, actual):\n",
    "    correct = 0\n",
    "    for p, a in zip(predicted, actual):\n",
    "        correct += 1 if p == a else 0\n",
    "    return 100 * correct / len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_matrix(corpus):\n",
    "    n = len(corpus)\n",
    "    print(n, \" documents in corpus.\")\n",
    "    all_words = []\n",
    "    for sent in corpus:\n",
    "        words = get_words(sent)\n",
    "        for word in words:\n",
    "            if word not in all_words:\n",
    "                all_words.append(word)\n",
    "    m = len(all_words)# number of words in corpus\n",
    "    print(m, \" words in corpus.\")\n",
    "    doc_count = np.zeros(m)\n",
    "    count_matrix = np.zeros((n,m))\n",
    "    for i in range(n):\n",
    "        sent_i = remove_special_chars(corpus[i].lower())\n",
    "        for j in range(m):\n",
    "            word_j = all_words[j]\n",
    "            if word_j in sent_i:\n",
    "                doc_count[j] += 1\n",
    "                for word in get_words(sent_i):\n",
    "                    if word == word_j:\n",
    "                        count_matrix[i][j] += 1\n",
    "    return count_matrix, all_words, doc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_matrix(corpus, count_matrix, doc_count):\n",
    "    n,m = count_matrix.shape\n",
    "    tfidf_matrix = np.zeros((n,m))\n",
    "    print(tfidf_matrix.shape)\n",
    "    print(count_matrix.shape)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            tf = count_matrix[i][j] / sum(count_matrix[i][:])\n",
    "            idf = math.log(n / doc_count[j])\n",
    "            tfidf_matrix[i][j] = tf * idf\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12143  documents in corpus.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python36\\Lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Program Files\\Python36\\Lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-ad3c55116db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcount_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_count_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmichael\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'line_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtfidf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tfidf_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmichael\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'line_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-116-da1df16578eb>\u001b[0m in \u001b[0;36mget_count_matrix\u001b[1;34m(corpus)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mall_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_special_chars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\Lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   3101\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3102\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 3103\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   3104\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3105\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "count_matrix, all_words, doc_count = get_count_matrix(michael['line_text'])\n",
    "tfidf_matrix = get_tfidf_matrix(michael['line_text'], count_matrix, doc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_matrix_to_file(count_matrix, all_words, \"count_matrix.csv\")\n",
    "write_matrix_to_file(tfidf_matrix, all_words, \"tfidf_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_matrix_to_file(matrix, words, output):\n",
    "    header = \"\"\n",
    "    for i in range(len(words)-1):\n",
    "        header += words[i] + \",\"\n",
    "    header += all_words[len(words)-1]\n",
    "    np.savetxt(output, matrix, delimiter=\",\",fmt='%.4e',header=header,comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
